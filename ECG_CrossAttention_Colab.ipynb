{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ«€ ECG Cross-Attention Auto Experiment\n",
        "\n",
        "MIT-BIH Arrhythmia Databaseë¥¼ ì‚¬ìš©í•œ ECG ë¶€ì •ë§¥ ë¶„ë¥˜ **ìë™ ì‹¤í—˜**\n",
        "\n",
        "## ì‹¤í—˜ ëª©ë¡\n",
        "| ëª¨ë¸ | * (DS1 ì „ì²´ 22ëª…) | @ (DS1-1/DS1-2 split) |\n",
        "|------|-------------------|----------------------|\n",
        "| **A0** (Baseline, Dense) | A0* | A0@ |\n",
        "| **A1** (Naive Concat, Dense) | A1* | A1@ |\n",
        "| **A2** (Cross Attention, Dense) | A2* | A2@ |\n",
        "| **B0** (Baseline, No Dense) | B0* | B0@ |\n",
        "| **B1** (Naive Concat, No Dense) | B1* | B1@ |\n",
        "| **B2** (Cross Attention, No Dense) | B2* | B2@ |\n",
        "\n",
        "**ë¶„ë¥˜ í´ë˜ìŠ¤ (AAMI 4-class)**: N, S, V, F\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1ï¸âƒ£ í™˜ê²½ ì„¤ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU í™•ì¸\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "!pip install -q wfdb openpyxl neurokit2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GitHubì—ì„œ í”„ë¡œì íŠ¸ clone\n",
        "!git clone https://github.com/h4xryu/ECG_CrossAttention.git\n",
        "%cd ECG_CrossAttention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2ï¸âƒ£ Google Drive ë§ˆìš´íŠ¸ & ë°ì´í„° ì—°ê²°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Drive ë§ˆìš´íŠ¸\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"âœ… Google Drive ë§ˆìš´íŠ¸ ì™„ë£Œ!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Google Driveì˜ ë°ì´í„° ê²½ë¡œ\n",
        "DRIVE_DATA_PATH = '/content/drive/MyDrive/ECG_Data/mit-bih-arrhythmia-database-1.0.0/'\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ë°ì´í„° í´ë” ìƒì„± ë° ì‹¬ë³¼ë¦­ ë§í¬\n",
        "os.makedirs('./data', exist_ok=True)\n",
        "\n",
        "# ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„± (ì´ë¯¸ ìˆìœ¼ë©´ ì‚­ì œ í›„ ì¬ìƒì„±)\n",
        "link_path = './data/mit-bih-arrhythmia-database-1.0.0'\n",
        "if os.path.islink(link_path):\n",
        "    os.unlink(link_path)\n",
        "elif os.path.exists(link_path):\n",
        "    import shutil\n",
        "    shutil.rmtree(link_path)\n",
        "\n",
        "os.symlink(DRIVE_DATA_PATH, link_path)\n",
        "\n",
        "# ë°ì´í„° í™•ì¸\n",
        "print(\"ğŸ“‚ ë°ì´í„° ê²½ë¡œ:\", link_path)\n",
        "print(\"\\níŒŒì¼ ëª©ë¡:\")\n",
        "!ls -la {link_path} | head -20\n",
        "\n",
        "# ë ˆì½”ë“œ ìˆ˜ í™•ì¸\n",
        "dat_files = [f for f in os.listdir(link_path) if f.endswith('.dat')]\n",
        "print(f\"\\nâœ… ì´ {len(dat_files)}ê°œ ë ˆì½”ë“œ í™•ì¸ë¨\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3ï¸âƒ£ ìë™ ì‹¤í—˜ ì„¤ì • í™•ì¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# main_autoexp.py ì„¤ì • í™•ì¸\n",
        "from main_autoexp import (\n",
        "    EXPERIMENTS, EPOCHS, BATCH_SIZE, LR, CLASSES,\n",
        "    DS1_FULL, DS1_TRAIN_SPLIT, DS1_VALID_SPLIT, DS2_TEST,\n",
        "    MODEL_CONFIG, OUTPUT_PATH\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ”¬ ìë™ ì‹¤í—˜ ì„¤ì •\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"ì´ ì‹¤í—˜ ìˆ˜: {len(EXPERIMENTS)}\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Learning Rate: {LR}\")\n",
        "print(f\"Classes: {CLASSES}\")\n",
        "print(f\"Output: {OUTPUT_PATH}\")\n",
        "\n",
        "print(\"\\nğŸ“‹ ì‹¤í—˜ ëª©ë¡:\")\n",
        "for exp_name, model_type, data_config in EXPERIMENTS:\n",
        "    config_str = \"DS1 ì „ì²´ 22ëª…\" if data_config == 'star' else \"DS1-1(17)/DS1-2(5) split\"\n",
        "    print(f\"  {exp_name:6s} | {model_type:25s} | {config_str}\")\n",
        "\n",
        "print(f\"\\nğŸ“‚ ë°ì´í„°:\")\n",
        "print(f\"  DS1 Full ({len(DS1_FULL)}ëª…): {DS1_FULL[:5]}...\")\n",
        "print(f\"  DS1-1 Train ({len(DS1_TRAIN_SPLIT)}ëª…): {DS1_TRAIN_SPLIT[:5]}...\")\n",
        "print(f\"  DS1-2 Valid ({len(DS1_VALID_SPLIT)}ëª…): {DS1_VALID_SPLIT}\")\n",
        "print(f\"  DS2 Test ({len(DS2_TEST)}ëª…): {DS2_TEST[:5]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# [ì„ íƒ] ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì—í­ ìˆ˜ ë³€ê²½\n",
        "# ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ë©´ 5 ì—í­ìœ¼ë¡œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥\n",
        "\n",
        "# !sed -i 's/EPOCHS = 50/EPOCHS = 5/' main_autoexp.py\n",
        "# !grep \"^EPOCHS\" main_autoexp.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4ï¸âƒ£ ìë™ ì‹¤í—˜ ì‹¤í–‰ (12ê°œ ì‹¤í—˜)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸš€ ìë™ ì‹¤í—˜ ì‹¤í–‰ (12ê°œ ì‹¤í—˜ x 50 ì—í­)\n",
        "# ì˜ˆìƒ ì†Œìš” ì‹œê°„: GPUì— ë”°ë¼ ë‹¤ë¦„ (T4 ê¸°ì¤€ ì•½ 6-8ì‹œê°„)\n",
        "!python main_autoexp.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê²°ê³¼ í´ë” í™•ì¸\n",
        "!ls -la auto_results/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì „ì²´ ê²°ê³¼ ìš”ì•½ Excel í™•ì¸\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "summary_files = sorted(glob.glob('auto_results/Results_Summary_*.xlsx'))\n",
        "if summary_files:\n",
        "    latest_summary = summary_files[-1]\n",
        "    print(f\"ğŸ“Š ê²°ê³¼ ìš”ì•½ íŒŒì¼: {latest_summary}\")\n",
        "    \n",
        "    df = pd.read_excel(latest_summary, sheet_name='Performance Metrics', header=None)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Performance Metrics Summary\")\n",
        "    print(\"=\"*80)\n",
        "    print(df.to_string())\n",
        "else:\n",
        "    print(\"âŒ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‹¤í—˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê°œë³„ ì‹¤í—˜ ê²°ê³¼ í™•ì¸\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "exp_dirs = sorted(glob.glob('auto_results/A*') + glob.glob('auto_results/B*'))\n",
        "print(f\"ğŸ“‚ ì´ {len(exp_dirs)}ê°œ ì‹¤í—˜ í´ë”\")\n",
        "\n",
        "for exp_dir in exp_dirs[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ\n",
        "    xlsx_files = glob.glob(f'{exp_dir}/*.xlsx')\n",
        "    for xlsx in xlsx_files:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ğŸ“Š {xlsx}\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        df_macro = pd.read_excel(xlsx, sheet_name='Macro')\n",
        "        print(df_macro.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix ì´ë¯¸ì§€ í‘œì‹œ (ëª¨ë“  ì‹¤í—˜)\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "exp_dirs = sorted(glob.glob('auto_results/A*') + glob.glob('auto_results/B*'))\n",
        "\n",
        "for exp_dir in exp_dirs:\n",
        "    png_files = glob.glob(f'{exp_dir}/*.png')\n",
        "    for png in png_files:\n",
        "        print(f\"\\nğŸ“Š {png}\")\n",
        "        display(Image(filename=png, width=400))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5ï¸âƒ£ ê²°ê³¼ë¥¼ Google Driveì— ì €ì¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# auto_results í´ë” ì „ì²´ë¥¼ Google Driveë¡œ ë³µì‚¬\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "src_path = './auto_results'\n",
        "dest_path = '/content/drive/MyDrive/ECG_AutoExp_Results'\n",
        "\n",
        "if os.path.exists(src_path):\n",
        "    # ê¸°ì¡´ í´ë” ì‚­ì œ í›„ ë³µì‚¬\n",
        "    if os.path.exists(dest_path):\n",
        "        shutil.rmtree(dest_path)\n",
        "    shutil.copytree(src_path, dest_path)\n",
        "    print(f\"âœ… ì „ì²´ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {dest_path}\")\n",
        "    !ls -la {dest_path}\n",
        "else:\n",
        "    print(\"âŒ auto_results í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‹¤í—˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê²°ê³¼ ìš”ì•½ Excelë§Œ ë‹¤ìš´ë¡œë“œ\n",
        "import glob\n",
        "from google.colab import files\n",
        "\n",
        "summary_files = glob.glob('auto_results/Results_Summary_*.xlsx')\n",
        "if summary_files:\n",
        "    for f in summary_files:\n",
        "        files.download(f)\n",
        "        print(f\"ğŸ“¥ ë‹¤ìš´ë¡œë“œ: {f}\")\n",
        "else:\n",
        "    print(\"âŒ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ“ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (5 ì—í­, ì„ íƒëœ ì‹¤í—˜ë§Œ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ì„¤ì • ë³€ê²½ (5 ì—í­, A2*ì™€ B2*ë§Œ)\n",
        "!sed -i 's/EPOCHS = 50/EPOCHS = 5/' main_autoexp.py\n",
        "\n",
        "# ì‹¤í—˜ ëª©ë¡ ì¶•ì†Œ (A2*, B2* ë§Œ)\n",
        "!sed -i \"s/EXPERIMENTS = \\\\[/EXPERIMENTS = [\\\\n    ('A2*', 'cross_attention', 'star'),\\\\n    ('B2*', 'cross_attention_B', 'star'),\\\\n] # QUICK_TEST\\\\nEXPERIMENTS_FULL = [/\" main_autoexp.py\n",
        "\n",
        "# ë³€ê²½ í™•ì¸\n",
        "!grep -E \"^EPOCHS|EXPERIMENTS\" main_autoexp.py | head -5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (2ê°œ ì‹¤í—˜ x 5 ì—í­)\n",
        "!python main_autoexp.py\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
